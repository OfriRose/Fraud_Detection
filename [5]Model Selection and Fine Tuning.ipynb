{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18ccf567",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, log_loss\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from typing import Dict, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d48d5925",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_pickle('train_set_final_filtered.pkl').drop(columns=['is_fraud'])\n",
    "y_train = pd.read_pickle('train_set_final_filtered.pkl')['is_fraud']\n",
    "X_dev = pd.read_pickle('dev_set_final_filtered.pkl').drop(columns=['is_fraud'])\n",
    "y_dev = pd.read_pickle('dev_set_final_filtered.pkl')['is_fraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bade24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classification_metrics(y_true: pd.Series, y_pred: np.ndarray, y_proba: np.ndarray) -> Dict[str, float]:\n",
    "    \"\"\"Calculates all key classification metrics, focusing on the minority class (1).\"\"\"\n",
    "    return {\n",
    "        'Accuracy': accuracy_score(y_true, y_pred),\n",
    "        'Precision': precision_score(y_true, y_pred, zero_division=0),\n",
    "        'Recall': recall_score(y_true, y_pred, zero_division=0),\n",
    "        'F1-Score': f1_score(y_true, y_pred, zero_division=0),\n",
    "        'Log-loss': log_loss(y_true, y_proba),\n",
    "        'AUC': roc_auc_score(y_true, y_proba)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4507dac9",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "904f8368",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddf97a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_models = {\n",
    "    'Logistic Regression': LogisticRegression(solver='saga', C=0.1, random_state=42, max_iter=2000), \n",
    "    'Decision Tree': DecisionTreeClassifier(max_depth=6, random_state=42), \n",
    "    'RandomForest': RandomForestClassifier(n_estimators=100, max_depth=8, random_state=42, n_jobs=-1),\n",
    "    'GBM': GradientBoostingClassifier(n_estimators=100, max_depth=5, random_state=42),\n",
    "    'ADABoost': AdaBoostClassifier(n_estimators=100, random_state=42, estimator=DecisionTreeClassifier(max_depth=2)),\n",
    "    'XGB': xgb.XGBClassifier(objective='binary:logistic', use_label_encoder=False, eval_metric='logloss', random_state=42, n_jobs=-1),\n",
    "    #SVM removed due to long training times\n",
    "    #'SVM': SVC(probability=True)\n",
    "}   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8148360",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_comparison(models: Dict[str, Any], X_train: pd.DataFrame, y_train: pd.Series, X_dev: pd.DataFrame, y_dev: pd.Series) -> pd.DataFrame:\n",
    "    \"\"\"Trains and evaluates the baseline models with stratified class weighting.\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    #Calculates the imbalance ratio for class weighting\n",
    "    imbalance_ratio = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "    class_weights = {0: 1, 1: imbalance_ratio}\n",
    "\n",
    "    for name, model in models.items():\n",
    "        print(f\"-> Training {name}...\")\n",
    "        \n",
    "        # --- Imbalance Handling ---\n",
    "        if name in ['Logistic Regression', 'Decision Tree', 'RandomForest']:\n",
    "             model.set_params(class_weight=class_weights)\n",
    "        elif name == 'XGB':\n",
    "             model.set_params(scale_pos_weight=imbalance_ratio)\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = model.predict(X_dev)\n",
    "        \n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            y_proba = model.predict_proba(X_dev)[:, 1]\n",
    "        elif hasattr(model, \"decision_function\"):\n",
    "            y_proba = model.predict_proba(X_dev)[:, 1]\n",
    "        else:\n",
    "            y_proba = y_pred \n",
    "\n",
    "        metrics = get_classification_metrics(y_dev, y_pred, y_proba)\n",
    "        metrics['model'] = name\n",
    "        results.append(metrics)\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8191dda9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training Logistic Regression...\n",
      "-> Training Decision Tree...\n",
      "-> Training RandomForest...\n",
      "-> Training GBM...\n",
      "-> Training ADABoost...\n",
      "-> Training XGB...\n",
      "\n",
      "=====================================================================================\n",
      "             BASELINE MODEL PERFORMANCE COMPARISON (on Validation Set)\n",
      "=====================================================================================\n",
      "|    | model               |   Accuracy |   Precision |   Recall |   F1-Score |   Log-loss |      AUC |\n",
      "|---:|:--------------------|-----------:|------------:|---------:|-----------:|-----------:|---------:|\n",
      "|  0 | XGB                 |   0.996127 |    0.586503 | 0.962668 |   0.728916 |   0.011413 | 0.997407 |\n",
      "|  1 | ADABoost            |   0.998868 |    0.970160 | 0.815789 |   0.886303 |   0.399857 | 0.995788 |\n",
      "|  2 | RandomForest        |   0.986852 |    0.286289 | 0.958384 |   0.440878 |   0.089809 | 0.994249 |\n",
      "|  3 | Logistic Regression |   0.973167 |    0.160512 | 0.936353 |   0.274046 |   0.094169 | 0.986303 |\n",
      "|  4 | Decision Tree       |   0.989136 |    0.324307 | 0.930845 |   0.481025 |   0.094036 | 0.966176 |\n",
      "|  5 | GBM                 |   0.998659 |    0.956199 | 0.788250 |   0.864140 |   0.019728 | 0.914191 |\n"
     ]
    }
   ],
   "source": [
    "comparison_df = run_model_comparison(baseline_models, X_train, y_train, X_dev, y_dev)\n",
    "\n",
    "comparison_df = comparison_df.sort_values(by='AUC', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*85)\n",
    "print(\"             BASELINE MODEL PERFORMANCE COMPARISON (on Validation Set)\")\n",
    "print(\"=\"*85)\n",
    "\n",
    "comparison_df = comparison_df[['model', 'Accuracy', 'Precision', 'Recall', 'F1-Score', 'Log-loss', 'AUC']]\n",
    "print(comparison_df.to_markdown(index=True, floatfmt=\".6f\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1e9a86",
   "metadata": {},
   "source": [
    "Fine Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b4c3f1",
   "metadata": {},
   "source": [
    "using a manual search due to a bug in the RandomizedSearchCV wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e07b58cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "imbalance_ratio = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "def evaluate_xgb_params(params: dict, X_train: pd.DataFrame, y_train: pd.Series, X_dev: pd.DataFrame, y_dev: pd.Series):\n",
    "    \"\"\"Trains XGBoost with a given parameter set and evaluates on the Dev set.\"\"\"\n",
    "    \n",
    "    model = xgb.XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss',\n",
    "        scale_pos_weight=imbalance_ratio,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        **params \n",
    "    )\n",
    "\n",
    "    print(f\"  -> Fitting model with max_depth={params['max_depth']}, learning_rate={params['learning_rate']}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_proba = model.predict_proba(X_dev)[:, 1]\n",
    "    \n",
    "    y_pred = model.predict(X_dev)\n",
    "    \n",
    "    auc = roc_auc_score(y_dev, y_proba)\n",
    "    recall = recall_score(y_dev, y_pred, zero_division=0)\n",
    "    precision = precision_score(y_dev, y_pred, zero_division=0)\n",
    "\n",
    "    return auc, recall, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6924cd31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "STARTING MANUAL XGBOOST FINE-TUNING\n",
      "==================================================\n",
      "  -> Fitting model with max_depth=6, learning_rate=0.1...\n",
      "  -> Fitting model with max_depth=8, learning_rate=0.05...\n",
      "  -> Fitting model with max_depth=4, learning_rate=0.2...\n",
      "\n",
      "--- Manual Tuning Results (Sorted by AUC) ---\n",
      "|    Set |   Max_Depth |   Learning_Rate |    AUC |   Recall |   Precision |\n",
      "|-------:|------------:|----------------:|-------:|---------:|------------:|\n",
      "| 1.0000 |      6.0000 |          0.1000 | 0.9974 |   0.9712 |      0.4383 |\n",
      "| 2.0000 |      8.0000 |          0.0500 | 0.9974 |   0.9651 |      0.5743 |\n",
      "| 3.0000 |      4.0000 |          0.2000 | 0.9971 |   0.9743 |      0.3567 |\n",
      "\n",
      "Recommended Best Hyperparameters: {'n_estimators': 150, 'max_depth': 6, 'learning_rate': 0.1, 'gamma': 0.5}\n"
     ]
    }
   ],
   "source": [
    "parameter_sets = [\n",
    "    {'n_estimators': 150, 'max_depth': 6, 'learning_rate': 0.1, 'gamma': 0.5},\n",
    "    \n",
    "    {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.05, 'gamma': 0.1},\n",
    "    \n",
    "    {'n_estimators': 100, 'max_depth': 4, 'learning_rate': 0.2, 'gamma': 1},\n",
    "]\n",
    "\n",
    "manual_results = []\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"STARTING MANUAL XGBOOST FINE-TUNING\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for i, params in enumerate(parameter_sets):\n",
    "    auc, recall, precision = evaluate_xgb_params(params, X_train, y_train, X_dev, y_dev)\n",
    "    \n",
    "    manual_results.append({\n",
    "        'Set': i + 1,\n",
    "        'Max_Depth': params['max_depth'],\n",
    "        'Learning_Rate': params['learning_rate'],\n",
    "        'AUC': auc,\n",
    "        'Recall': recall,\n",
    "        'Precision': precision\n",
    "    })\n",
    "    \n",
    "results_df = pd.DataFrame(manual_results).sort_values(by='AUC', ascending=False)\n",
    "print(\"\\n--- Manual Tuning Results (Sorted by AUC) ---\")\n",
    "print(results_df.to_markdown(index=False, floatfmt=\".4f\"))\n",
    "\n",
    "best_set_index = results_df.iloc[0]['Set']\n",
    "\n",
    "best_params_index = int(best_set_index) - 1\n",
    "best_params = parameter_sets[best_params_index]\n",
    "\n",
    "print(f\"\\nRecommended Best Hyperparameters: {best_params}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
