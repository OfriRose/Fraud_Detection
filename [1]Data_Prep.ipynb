{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc04284e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install kaggle\n",
    "#!pip install kagglehub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f2a12f",
   "metadata": {},
   "source": [
    "Importing all 2020 data in chunks for better run time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "337b0b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded and filtered dataset. Total 2020 records: 17,292,422\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "CHUNKSIZE = 50000\n",
    "date_column = 'trans_date'\n",
    "all_2020_chunks = []\n",
    "\n",
    "for chunk in pd.read_csv('credit_card_fraud.csv', chunksize=CHUNKSIZE, parse_dates=[date_column]):\n",
    "\n",
    "    # Filter each chunk for the year 2020\n",
    "    df_2020_chunk = chunk[chunk[date_column].dt.year == 2020]\n",
    "    all_2020_chunks.append(df_2020_chunk)\n",
    "\n",
    "df = pd.concat(all_2020_chunks, ignore_index=True)\n",
    "\n",
    "print(f\"Successfully loaded and filtered dataset. Total 2020 records: {len(df):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60f188ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17292422 entries, 0 to 17292421\n",
      "Data columns (total 27 columns):\n",
      " #   Column      Dtype         \n",
      "---  ------      -----         \n",
      " 0   Unnamed: 0  int64         \n",
      " 1   ssn         object        \n",
      " 2   cc_num      int64         \n",
      " 3   first       object        \n",
      " 4   last        object        \n",
      " 5   gender      object        \n",
      " 6   street      object        \n",
      " 7   city        object        \n",
      " 8   state       object        \n",
      " 9   zip         int64         \n",
      " 10  lat         float64       \n",
      " 11  long        float64       \n",
      " 12  city_pop    int64         \n",
      " 13  job         object        \n",
      " 14  dob         object        \n",
      " 15  acct_num    int64         \n",
      " 16  profile     object        \n",
      " 17  trans_num   object        \n",
      " 18  trans_date  datetime64[ns]\n",
      " 19  trans_time  object        \n",
      " 20  unix_time   int64         \n",
      " 21  category    object        \n",
      " 22  amt         float64       \n",
      " 23  is_fraud    int64         \n",
      " 24  merchant    object        \n",
      " 25  merch_lat   float64       \n",
      " 26  merch_long  float64       \n",
      "dtypes: datetime64[ns](1), float64(5), int64(7), object(14)\n",
      "memory usage: 3.5+ GB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a09006",
   "metadata": {},
   "source": [
    "##choosing a state to focus on based on most absolute fraud cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a32810dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Top 3 States by Absolute Fraud Count ---\n",
      "| state   |   is_fraud |\n",
      "|:--------|-----------:|\n",
      "| CA      |      10894 |\n",
      "| TX      |       7344 |\n",
      "| NY      |       5945 |\n",
      "\n",
      "Recommendation: The state to focus on is **'CA'** with **10894** fraud cases.\n"
     ]
    }
   ],
   "source": [
    "fraud_counts = df.groupby('state')['is_fraud'].sum().reset_index()\n",
    "top_fraud_states = fraud_counts.sort_values(by='is_fraud', ascending=False)\n",
    "\n",
    "print(\"--- Top 3 States by Absolute Fraud Count ---\")\n",
    "print(top_fraud_states.head(3).to_markdown(index=False))\n",
    "\n",
    "best_state_to_keep = top_fraud_states.iloc[0]['state']\n",
    "best_fraud_count = top_fraud_states.iloc[0]['is_fraud']\n",
    "\n",
    "print(f\"\\nRecommendation: The state to focus on is **'{best_state_to_keep}'** with **{best_fraud_count}** fraud cases.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1104a5f",
   "metadata": {},
   "source": [
    "#scoping data on California"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1eda7fbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "287"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ca_mask = (df['state'] == 'CA')\n",
    "clean_df = df[ca_mask].copy()\n",
    "\n",
    "del df\n",
    "import gc\n",
    "gc.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "87cb426e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2013945 entries, 0 to 17284449\n",
      "Data columns (total 27 columns):\n",
      " #   Column      Dtype         \n",
      "---  ------      -----         \n",
      " 0   Unnamed: 0  int64         \n",
      " 1   ssn         object        \n",
      " 2   cc_num      int64         \n",
      " 3   first       object        \n",
      " 4   last        object        \n",
      " 5   gender      object        \n",
      " 6   street      object        \n",
      " 7   city        object        \n",
      " 8   state       object        \n",
      " 9   zip         int64         \n",
      " 10  lat         float64       \n",
      " 11  long        float64       \n",
      " 12  city_pop    int64         \n",
      " 13  job         object        \n",
      " 14  dob         object        \n",
      " 15  acct_num    int64         \n",
      " 16  profile     object        \n",
      " 17  trans_num   object        \n",
      " 18  trans_date  datetime64[ns]\n",
      " 19  trans_time  object        \n",
      " 20  unix_time   int64         \n",
      " 21  category    object        \n",
      " 22  amt         float64       \n",
      " 23  is_fraud    int64         \n",
      " 24  merchant    object        \n",
      " 25  merch_lat   float64       \n",
      " 26  merch_long  float64       \n",
      "dtypes: datetime64[ns](1), float64(5), int64(7), object(14)\n",
      "memory usage: 430.2+ MB\n"
     ]
    }
   ],
   "source": [
    "clean_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c52b7c4",
   "metadata": {},
   "source": [
    "##Consolidates high cardinality features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3748078c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def consolidate_top_categories(df: pd.DataFrame, column_name: str, top_n: int = 20) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Consolidates low-frequency values in a specified column into an 'Other' category to reduce cardinality.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "        column_name (str): The name of the column to consolidate.\n",
    "        top_n (int): The number of top-most frequent categories to keep. \n",
    "                     All others will be labeled 'Other'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with the specified column modified.\n",
    "    \"\"\"\n",
    "    top_categories = df[column_name].value_counts().nlargest(top_n).index\n",
    "\n",
    "    df[column_name] = df[column_name].where(\n",
    "        df[column_name].isin(top_categories), \n",
    "        'Other'\n",
    "    )\n",
    "    \n",
    "    # 3. Print the results for verification\n",
    "    print(f\"--- Value Counts for '{column_name}' after Consolidation ---\")\n",
    "    print(df[column_name].value_counts().to_markdown())\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b5d4baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Value Counts for 'city' after Consolidation ---\n",
      "| city           |            count |\n",
      "|:---------------|-----------------:|\n",
      "| Other          |      1.40941e+06 |\n",
      "| Los Angeles    | 131821           |\n",
      "| San Jose       |  59422           |\n",
      "| San Diego      |  46185           |\n",
      "| San Francisco  |  40430           |\n",
      "| Sacramento     |  35189           |\n",
      "| Fresno         |  28433           |\n",
      "| Riverside      |  26704           |\n",
      "| Long Beach     |  25085           |\n",
      "| Bakersfield    |  24839           |\n",
      "| Chula Vista    |  19786           |\n",
      "| Santa Ana      |  19781           |\n",
      "| Oakland        |  17438           |\n",
      "| Corona         |  17411           |\n",
      "| Anaheim        |  17334           |\n",
      "| Oxnard         |  17213           |\n",
      "| San Bernardino |  17196           |\n",
      "| Stockton       |  15872           |\n",
      "| Glendale       |  15138           |\n",
      "| Fremont        |  14937           |\n",
      "| Oceanside      |  14323           |\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clean_df = consolidate_top_categories(clean_df, 'city', top_n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6490bf47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Value Counts for 'merchant' after Consolidation ---\n",
      "| merchant                            |          count |\n",
      "|:------------------------------------|---------------:|\n",
      "| Other                               |    1.86064e+06 |\n",
      "| fraud_O'Connell, Botsford and Hand  | 7786           |\n",
      "| fraud_Reilly LLC                    | 7754           |\n",
      "| fraud_Botsford PLC                  | 7716           |\n",
      "| fraud_Champlin-Casper               | 7708           |\n",
      "| fraud_Wuckert-Goldner               | 7674           |\n",
      "| fraud_Botsford and Sons             | 7674           |\n",
      "| fraud_Windler, Goodwin and Kovacek  | 7671           |\n",
      "| fraud_Schmidt-Larkin                | 7669           |\n",
      "| fraud_Hettinger, McCullough and Fay | 7669           |\n",
      "| fraud_Schiller, Blanda and Johnson  | 7660           |\n",
      "| fraud_Pollich LLC                   | 7655           |\n",
      "| fraud_White and Sons                | 7646           |\n",
      "| fraud_Cole, Hills and Jewess        | 7645           |\n",
      "| fraud_Padberg-Sauer                 | 7638           |\n",
      "| fraud_Crist, Jakubowski and Littel  | 7638           |\n",
      "| fraud_Denesik, Powlowski and Pouros | 7636           |\n",
      "| fraud_Witting, Beer and Ernser      | 7634           |\n",
      "| fraud_Champlin and Sons             | 7615           |\n",
      "| fraud_Lynch-Wisozk                  | 7611           |\n",
      "| fraud_Gutmann, McLaughlin and Wiza  | 7611           |\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clean_df = consolidate_top_categories(clean_df, 'merchant', top_n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1d1de9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Value Counts for 'job' after Consolidation ---\n",
      "| job                                           |           count |\n",
      "|:----------------------------------------------|----------------:|\n",
      "| Other                                         |     1.84333e+06 |\n",
      "| Patent attorney                               | 12343           |\n",
      "| Child psychotherapist                         | 10910           |\n",
      "| Social researcher                             | 10651           |\n",
      "| Information systems manager                   |  9887           |\n",
      "| Armed forces operational officer              |  9261           |\n",
      "| Surveyor, minerals                            |  8836           |\n",
      "| Engineer, structural                          |  8764           |\n",
      "| Magazine journalist                           |  8464           |\n",
      "| Engineer, mining                              |  8438           |\n",
      "| Art therapist                                 |  8052           |\n",
      "| Biomedical engineer                           |  8045           |\n",
      "| Film/video editor                             |  7972           |\n",
      "| Mining engineer                               |  7899           |\n",
      "| Community arts worker                         |  7377           |\n",
      "| Systems analyst                               |  7334           |\n",
      "| Engineer, building services                   |  7312           |\n",
      "| Chartered legal executive (England and Wales) |  7287           |\n",
      "| Production manager                            |  7278           |\n",
      "| Conservator, furniture                        |  7264           |\n",
      "| Charity fundraiser                            |  7243           |\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "clean_df = consolidate_top_categories(clean_df, 'job', top_n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "17a1ddfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['is_male'] = clean_df['gender'].apply(lambda x: 1 if x == 'M' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "983de5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['job'] = clean_df['job'].astype('string')\n",
    "clean_df['job'] = clean_df['job'].str.lower()\n",
    "clean_df['merchant'] = clean_df['merchant'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c739313b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['city'] = clean_df['city'].astype('string')\n",
    "clean_df['city'] = clean_df['city'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8e03f3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['dob'] = pd.to_datetime(clean_df['dob'])\n",
    "clean_df['trans_date'] = pd.to_datetime(clean_df['trans_date'])\n",
    "time_str = clean_df['trans_time'].astype('string')\n",
    "\n",
    "clean_df['trans_timestamp'] = clean_df['trans_date'].dt.strftime('%Y-%m-%d') + ' ' + time_str\n",
    "clean_df['trans_timestamp'] = pd.to_datetime(clean_df['trans_timestamp'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "clean_df['category'] = clean_df['category'].astype('string')\n",
    "clean_df['profile'] = clean_df['profile'].astype('string')\n",
    "clean_df['profile'] = clean_df['profile'].str.lower()\n",
    "clean_df['category'] = clean_df['category'].str.lower()\n",
    "\n",
    "clean_df['merchant'] = clean_df['merchant'].astype('string')\n",
    "clean_df['trans_num'] = clean_df['trans_num'].astype('string')\n",
    "clean_df['ssn'] = clean_df['ssn'].astype('string')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62c9547",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = clean_df.drop(columns=['first', 'last', 'street', 'unix_time', 'gender', 'state', 'trans_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "564691cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2013945 entries, 0 to 17284449\n",
      "Data columns (total 22 columns):\n",
      " #   Column           Dtype         \n",
      "---  ------           -----         \n",
      " 0   Unnamed: 0       int64         \n",
      " 1   ssn              string        \n",
      " 2   cc_num           int64         \n",
      " 3   city             string        \n",
      " 4   zip              int64         \n",
      " 5   lat              float64       \n",
      " 6   long             float64       \n",
      " 7   city_pop         int64         \n",
      " 8   job              string        \n",
      " 9   dob              datetime64[ns]\n",
      " 10  acct_num         int64         \n",
      " 11  profile          string        \n",
      " 12  trans_num        string        \n",
      " 13  trans_date       datetime64[ns]\n",
      " 14  category         string        \n",
      " 15  amt              float64       \n",
      " 16  is_fraud         int64         \n",
      " 17  merchant         string        \n",
      " 18  merch_lat        float64       \n",
      " 19  merch_long       float64       \n",
      " 20  is_male          int64         \n",
      " 21  trans_timestamp  datetime64[ns]\n",
      "dtypes: datetime64[ns](3), float64(5), int64(7), string(7)\n",
      "memory usage: 353.4 MB\n"
     ]
    }
   ],
   "source": [
    "clean_df.info(max_cols=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b5dcfaa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data saved successfully to: prepped_data.pkl\n"
     ]
    }
   ],
   "source": [
    "file_path = 'prepped_data.pkl'\n",
    "clean_df.to_pickle(file_path)\n",
    "\n",
    "print(f\"✅ Data saved successfully to: {file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
